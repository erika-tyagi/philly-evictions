{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Philly Evictions Analysis\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pipeline\n",
    "\n",
    "pipeline.notebook.set_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Our evictions data has already been augmented with data from the ACS and from\n",
    "Philadelphia's open data portal. We load in the final merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>year_evictions</th>\n",
       "      <th>evictions</th>\n",
       "      <th>low-flag</th>\n",
       "      <th>imputed</th>\n",
       "      <th>subbed</th>\n",
       "      <th>evictions_t-1</th>\n",
       "      <th>evictions_t-2</th>\n",
       "      <th>evictions_t-5</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>...</th>\n",
       "      <th>units</th>\n",
       "      <th>occupied_units</th>\n",
       "      <th>vacant_units</th>\n",
       "      <th>for_rent_units</th>\n",
       "      <th>num_af_am_alone</th>\n",
       "      <th>num_hisp</th>\n",
       "      <th>black_alone_owner_occupied</th>\n",
       "      <th>num_with_high_school_degree</th>\n",
       "      <th>num_with_ged</th>\n",
       "      <th>num_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2010</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID  year_evictions  evictions  low-flag  imputed  subbed  \\\n",
       "0  421010001001            2010       13.0         0        0       1   \n",
       "1  421010001001            2011        7.0         0        0       1   \n",
       "2  421010001001            2012        7.0         0        0       1   \n",
       "3  421010001001            2013        9.0         0        0       1   \n",
       "4  421010001001            2014        4.0         0        0       1   \n",
       "\n",
       "   evictions_t-1  evictions_t-2  evictions_t-5  crime_count  ...   units  \\\n",
       "0            8.0           10.0            9.0          NaN  ...   220.0   \n",
       "1           13.0            8.0            3.0          NaN  ...  1173.0   \n",
       "2            7.0           13.0           13.0        351.0  ...  1347.0   \n",
       "3            7.0            7.0           10.0        607.0  ...  1481.0   \n",
       "4            9.0            7.0            8.0        395.0  ...  1489.0   \n",
       "\n",
       "   occupied_units  vacant_units  for_rent_units num_af_am_alone num_hisp  \\\n",
       "0           189.0          94.0             0.0             0.0      0.0   \n",
       "1           934.0         728.0            38.0            76.0     94.0   \n",
       "2          1024.0         790.0           124.0           104.0    111.0   \n",
       "3          1094.0         826.0           139.0            88.0    122.0   \n",
       "4          1126.0         823.0           155.0            89.0     57.0   \n",
       "\n",
       "  black_alone_owner_occupied  num_with_high_school_degree  num_with_ged  \\\n",
       "0                        0.0                          NaN           NaN   \n",
       "1                       14.0                          NaN           NaN   \n",
       "2                       12.0                          NaN           NaN   \n",
       "3                       12.0                         52.0           0.0   \n",
       "4                       12.0                         53.0           0.0   \n",
       "\n",
       "   num_unemployed  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/final_merged_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data By Year\n",
    "We have data for 2009 to 2016. We want to split this data into training set /\n",
    "test set pairs using a temporal cross-validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_start train_end test_start test_end\n",
       "0        2010      2010       2011     2011\n",
       "1        2011      2011       2012     2012\n",
       "2        2012      2012       2013     2013\n",
       "3        2013      2013       2014     2014\n",
       "4        2014      2014       2015     2015\n",
       "5        2015      2015       2016     2016"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = pipeline.split_by_year(df, colname='year_evictions')\n",
    "pipeline.split_boundaries(splits, colname='year_evictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "We want to clean each of our training set / test set pairs. We use a function\n",
    "called `clean_split()` that cleans both sets at once, making sure to clean the\n",
    "test data using the same bins and categories applied to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mdef\u001b[0m \u001b[0mclean_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m    \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m    \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_overall_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m    \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_overall_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m    \u001b[0mfeatures_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feature_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m    \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \\\n",
      "        \u001b[0mclean_and_create_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\n",
      "\u001b[1;33m\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%psource pipeline.clean_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:959: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:959: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:959: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n"
     ]
    }
   ],
   "source": [
    "cleaned_splits = [pipeline.clean_split(split) for split in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labeling\n",
    "We plan to use both regression-based models and binary classifiers. For our\n",
    "binary classifiers, we will need to label our data using a binary label.\n",
    "\n",
    "Our binary label separates block groups into two classes: \"high\" and \"low\"\n",
    "eviction rate block groups. The \"high\" eviction rate block groups are those\n",
    "that we believe should be prioritized for intervention.\n",
    "\n",
    "Any block group with more than 14 evictions is considered a \"high\" eviction\n",
    "rate block group. Roughly 16% of Philadelphia block groups are \"high\" eviction\n",
    "rate block groups. We have picked this lower boundary because we know that\n",
    "Philadelphia can afford to target about 16% of block groups for intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_splits = [pipeline.label(split, lower_bound=14, drop_column=True)\n",
    "                  for split in cleaned_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Model Generation\n",
    "### Binary Classifiers\n",
    "Our binary classifiers are given by the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=1234, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                      weights='uniform'),\n",
       " 'DT': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                        max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort=False,\n",
       "                        random_state=1234, splitter='best'),\n",
       " 'SVM': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "     kernel='linear', max_iter=-1, probability=True, random_state=1234,\n",
       "     shrinking=True, tol=0.001, verbose=False),\n",
       " 'RF': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                        n_jobs=None, oob_score=False, random_state=1234,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'GB': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='auto',\n",
       "                            random_state=1234, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " 'AB': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                    n_estimators=50, random_state=1234),\n",
       " 'NB': GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " 'ET': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                      n_jobs=None, oob_score=False, random_state=1234, verbose=0,\n",
       "                      warm_start=False),\n",
       " 'BC': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                   max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                   n_jobs=None, oob_score=False, random_state=1234, verbose=0,\n",
       "                   warm_start=False)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We plan to run a grid search using the following hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1]},\n",
       " 'KNN': {'n_neighbors': [5, 10],\n",
       "  'weights': ['uniform', 'distance'],\n",
       "  'algorithm': ['auto', 'ball_tree', 'kd_tree']},\n",
       " 'DT': {'criterion': ['gini', 'entropy'],\n",
       "  'max_depth': [5, 50],\n",
       "  'max_features': [None],\n",
       "  'min_samples_split': [5, 10]},\n",
       " 'SVM': {'C': [0.01, 0.1]},\n",
       " 'RF': {'n_estimators': [100, 1000],\n",
       "  'max_depth': [5, 50],\n",
       "  'max_features': ['sqrt', 'log2'],\n",
       "  'min_samples_split': [5, 10]},\n",
       " 'GB': {'n_estimators': [100, 1000],\n",
       "  'learning_rate': [0.01, 0.05],\n",
       "  'subsample': [0.1, 0.5],\n",
       "  'max_depth': [5, 10]},\n",
       " 'AB': {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [100, 1000]},\n",
       " 'NB': {},\n",
       " 'ET': {'n_estimators': [100, 1000],\n",
       "  'criterion': ['gini', 'entropy'],\n",
       "  'max_depth': [5, 10],\n",
       "  'max_features': ['sqrt', 'log2'],\n",
       "  'min_samples_split': [5, 10]},\n",
       " 'BC': {'n_estimators': [100, 1000]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.clf_small_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We also want to evaluate our models at the following thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [12, 16, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We run our models for each of our splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with parameters {'C': 0.01, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.01, 'penalty': 'l2'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l2'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running SVM with parameters {'C': 0.01}\n",
      "Running SVM with parameters {'C': 0.1}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "Running NB with parameters {}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running BC with parameters {'n_estimators': 100}\n",
      "Running BC with parameters {'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with parameters {'C': 0.01, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.01, 'penalty': 'l2'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l2'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running SVM with parameters {'C': 0.01}\n",
      "Running SVM with parameters {'C': 0.1}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "Running NB with parameters {}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running BC with parameters {'n_estimators': 100}\n",
      "Running BC with parameters {'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with parameters {'C': 0.01, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.01, 'penalty': 'l2'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l2'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running SVM with parameters {'C': 0.01}\n",
      "Running SVM with parameters {'C': 0.1}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "Running NB with parameters {}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running BC with parameters {'n_estimators': 100}\n",
      "Running BC with parameters {'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with parameters {'C': 0.01, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.01, 'penalty': 'l2'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l2'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running SVM with parameters {'C': 0.01}\n",
      "Running SVM with parameters {'C': 0.1}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "Running NB with parameters {}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running BC with parameters {'n_estimators': 100}\n",
      "Running BC with parameters {'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with parameters {'C': 0.01, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.01, 'penalty': 'l2'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l2'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running SVM with parameters {'C': 0.01}\n",
      "Running SVM with parameters {'C': 0.1}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "Running NB with parameters {}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running BC with parameters {'n_estimators': 100}\n",
      "Running BC with parameters {'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with parameters {'C': 0.01, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.01, 'penalty': 'l2'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l1'}\n",
      "Running LR with parameters {'C': 0.1, 'penalty': 'l2'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Running KNN with parameters {'algorithm': 'kd_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_split': 10}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 5}\n",
      "Running DT with parameters {'criterion': 'entropy', 'max_depth': 50, 'max_features': None, 'min_samples_split': 10}\n",
      "Running SVM with parameters {'C': 0.01}\n",
      "Running SVM with parameters {'C': 0.1}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running RF with parameters {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}\n",
      "Running GB with parameters {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME', 'n_estimators': 1000}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Running AB with parameters {'algorithm': 'SAMME.R', 'n_estimators': 1000}\n",
      "Running NB with parameters {}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Running ET with parameters {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Running BC with parameters {'n_estimators': 100}\n",
      "Running BC with parameters {'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "models = pipeline.clfs\n",
    "grid = pipeline.clf_small_grid\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'split',\n",
    "    'classifier',\n",
    "    'parameters',\n",
    "    'threshold'\n",
    "] + pipeline.evaluate.ClassifierEvaluator.metric_names())\n",
    "\n",
    "for i, (train_df, test_df) in enumerate(labeled_splits, start=1):\n",
    "    train_df = train_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    test_df = test_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    df = pipeline.run_clf_loop(\n",
    "        test_df, train_df, models, grid, 'label', thresholds, debug=True\n",
    "    )\n",
    "\n",
    "    df = df.assign(split=i)\n",
    "    results_df = results_df.append(df, ignore_index=True)\n",
    "\n",
    "results_df.to_csv('results/clf-small-grid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models\n",
    "Our regression models are given by the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       " 'SVR': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "           intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "           random_state=None, tol=0.0001, verbose=0),\n",
       " 'DTR': DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       presort=False, random_state=None, splitter='best'),\n",
       " 'RFR': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.regs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We plan to run a grid search using the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': {},\n",
       " 'SVR': {'C': [0.01, 0.1]},\n",
       " 'DTR': {'max_depth': [5, 50],\n",
       "  'max_features': [None],\n",
       "  'min_samples_split': [2, 5, 10]},\n",
       " 'RFR': {'n_estimators': [100, 1000],\n",
       "  'max_depth': [5, 50],\n",
       "  'max_features': ['sqrt', 'log2'],\n",
       "  'min_samples_split': [2, 5, 10]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.reg_small_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We run our models for each of our splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/sinclairtarget/harris/ml/philly-evictions/.venv/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "models = pipeline.regs\n",
    "grid = pipeline.reg_small_grid\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'split',\n",
    "    'classifier',\n",
    "    'parameters',\n",
    "] + pipeline.evaluate.RegressionEvaluator.metric_names())\n",
    "\n",
    "for i, (train_df, test_df) in enumerate(cleaned_splits, start=1):\n",
    "    train_df = train_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    test_df = test_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    df = pipeline.run_reg_loop(\n",
    "        test_df, train_df, models, grid, 'evictions'\n",
    "    )\n",
    "\n",
    "    df = df.assign(split=i)\n",
    "    results_df = results_df.append(df, ignore_index=True)\n",
    "\n",
    "results_df.to_csv('results/reg-small-grid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
