{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Philly Evictions Analysis\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "pipeline.notebook.set_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Our evictions data has already been augmented with data from the ACS and from\n",
    "Philadelphia's open data portal. We load in the final merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>year_evictions</th>\n",
       "      <th>evictions</th>\n",
       "      <th>low-flag</th>\n",
       "      <th>imputed</th>\n",
       "      <th>subbed</th>\n",
       "      <th>evictions_t-1</th>\n",
       "      <th>evictions_t-2</th>\n",
       "      <th>evictions_t-5</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>violations_count</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_renter_households</th>\n",
       "      <th>renter_occupied_household_size</th>\n",
       "      <th>median_gross_rent</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>units</th>\n",
       "      <th>occupied_units</th>\n",
       "      <th>vacant_units</th>\n",
       "      <th>for_rent_units</th>\n",
       "      <th>num_white_alone</th>\n",
       "      <th>num_af_am_alone</th>\n",
       "      <th>num_hisp</th>\n",
       "      <th>black_alone_owner_occupied</th>\n",
       "      <th>num_with_high_school_degree</th>\n",
       "      <th>num_with_ged</th>\n",
       "      <th>num_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2010</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1805</td>\n",
       "      <td>157670</td>\n",
       "      <td>220.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1406</td>\n",
       "      <td>66319</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1398</td>\n",
       "      <td>68000</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1401</td>\n",
       "      <td>64208</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>421010001001</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>68750.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID  year_evictions  evictions  low-flag  imputed  subbed  \\\n",
       "0  421010001001            2010       13.0         0        0       1   \n",
       "1  421010001001            2011        7.0         0        0       1   \n",
       "2  421010001001            2012        7.0         0        0       1   \n",
       "3  421010001001            2013        9.0         0        0       1   \n",
       "4  421010001001            2014        4.0         0        0       1   \n",
       "\n",
       "   evictions_t-1  evictions_t-2  evictions_t-5  crime_count  violations_count  \\\n",
       "0            8.0           10.0            9.0          NaN               NaN   \n",
       "1           13.0            8.0            3.0          NaN               NaN   \n",
       "2            7.0           13.0           13.0        351.0               NaN   \n",
       "3            7.0            7.0           10.0        607.0               NaN   \n",
       "4            9.0            7.0            8.0        395.0               NaN   \n",
       "\n",
       "   total_population  total_households  total_renter_households  \\\n",
       "0             327.0             189.0                     94.0   \n",
       "1            1348.0             934.0                    728.0   \n",
       "2            1409.0            1024.0                    790.0   \n",
       "3            1546.0            1094.0                    826.0   \n",
       "4            1668.0            1126.0                    823.0   \n",
       "\n",
       "  renter_occupied_household_size median_gross_rent median_household_income  \\\n",
       "0                           1.98              1805                  157670   \n",
       "1                           1.50              1406                   66319   \n",
       "2                           1.39              1398                   68000   \n",
       "3                           1.43              1401                   64208   \n",
       "4                           1.46            1452.0                 68750.0   \n",
       "\n",
       "    units  occupied_units  vacant_units  for_rent_units  num_white_alone  \\\n",
       "0   220.0           189.0          94.0             0.0            312.0   \n",
       "1  1173.0           934.0         728.0            38.0           1147.0   \n",
       "2  1347.0          1024.0         790.0           124.0           1177.0   \n",
       "3  1481.0          1094.0         826.0           139.0           1305.0   \n",
       "4  1489.0          1126.0         823.0           155.0           1434.0   \n",
       "\n",
       "   num_af_am_alone  num_hisp  black_alone_owner_occupied  \\\n",
       "0              0.0       0.0                         0.0   \n",
       "1             76.0      94.0                        14.0   \n",
       "2            104.0     111.0                        12.0   \n",
       "3             88.0     122.0                        12.0   \n",
       "4             89.0      57.0                        12.0   \n",
       "\n",
       "   num_with_high_school_degree  num_with_ged  num_unemployed  \n",
       "0                          NaN           NaN             NaN  \n",
       "1                          NaN           NaN             NaN  \n",
       "2                          NaN           NaN             0.0  \n",
       "3                         52.0           0.0             0.0  \n",
       "4                         53.0           0.0             0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/final_merged_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data By Year\n",
    "We have data for 2009 to 2016. We want to split this data into training set /\n",
    "test set pairs using a temporal cross-validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_start train_end test_start test_end\n",
       "0        2010      2010       2011     2011\n",
       "1        2010      2011       2012     2012\n",
       "2        2010      2012       2013     2013\n",
       "3        2010      2013       2014     2014\n",
       "4        2010      2014       2015     2015\n",
       "5        2010      2015       2016     2016"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = pipeline.split_all_years(df, colname='year_evictions')\n",
    "pipeline.split_boundaries(splits, colname='year_evictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "We want to clean each of our training set / test set pairs. We use a function\n",
    "called `clean_split()` that cleans both sets at once, making sure to clean the\n",
    "test data using the same bins and categories applied to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mdef\u001b[0m \u001b[0mclean_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_overall_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_overall_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfeatures_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \\\n",
      "        \u001b[0mclean_and_create_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%psource pipeline.clean_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_splits = [pipeline.clean_split(split) for split in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labeling\n",
    "We plan to use both regression-based models and binary classifiers. For our\n",
    "binary classifiers, we will need to label our data using a binary label.\n",
    "\n",
    "Our binary label separates block groups into two classes: \"high\" and \"low\"\n",
    "eviction rate block groups. The \"high\" eviction rate block groups are those\n",
    "that we believe should be prioritized for intervention.\n",
    "\n",
    "Any block group with more than 14 evictions is considered a \"high\" eviction\n",
    "rate block group. Roughly 16% of Philadelphia block groups are \"high\" eviction\n",
    "rate block groups. We have picked this lower boundary because we know that\n",
    "Philadelphia can afford to target about 16% of block groups for intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_splits = [pipeline.label(split, lower_bound=14, drop_column=True)\n",
    "                  for split in cleaned_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Model Generation\n",
    "### Binary Classifiers\n",
    "Our binary classifiers are given by the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=1234, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'DT': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=1234,\n",
       "             splitter='best'),\n",
       " 'SVM': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "   kernel='linear', max_iter=-1, probability=True, random_state=1234,\n",
       "   shrinking=True, tol=0.001, verbose=False),\n",
       " 'RF': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "             oob_score=False, random_state=1234, verbose=0,\n",
       "             warm_start=False),\n",
       " 'GB': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               n_iter_no_change=None, presort='auto', random_state=1234,\n",
       "               subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " 'AB': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=1.0, n_estimators=50, random_state=1234),\n",
       " 'NB': GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " 'ET': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=1234, verbose=0, warm_start=False),\n",
       " 'BC': BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "          bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "          n_estimators=10, n_jobs=None, oob_score=False, random_state=1234,\n",
       "          verbose=0, warm_start=False),\n",
       " 'DC': DummyClassifier(constant=None, random_state=1234, strategy='most_frequent')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We plan to run a grid search using the following hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1]},\n",
       " 'KNN': {'n_neighbors': [5, 10],\n",
       "  'weights': ['uniform', 'distance'],\n",
       "  'algorithm': ['auto', 'ball_tree', 'kd_tree']},\n",
       " 'DT': {'criterion': ['gini', 'entropy'],\n",
       "  'max_depth': [5, 50],\n",
       "  'max_features': [None],\n",
       "  'min_samples_split': [5, 10]},\n",
       " 'SVM': {'C': [0.01, 0.1]},\n",
       " 'RF': {'n_estimators': [100, 1000],\n",
       "  'max_depth': [5, 50],\n",
       "  'max_features': ['sqrt', 'log2'],\n",
       "  'min_samples_split': [5, 10]},\n",
       " 'GB': {'n_estimators': [100, 1000],\n",
       "  'learning_rate': [0.01, 0.05],\n",
       "  'subsample': [0.1, 0.5],\n",
       "  'max_depth': [5, 10]},\n",
       " 'AB': {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [100, 1000]},\n",
       " 'NB': {},\n",
       " 'ET': {'n_estimators': [100, 1000],\n",
       "  'criterion': ['gini', 'entropy'],\n",
       "  'max_depth': [5, 10],\n",
       "  'max_features': ['sqrt', 'log2'],\n",
       "  'min_samples_split': [5, 10]},\n",
       " 'BC': {'n_estimators': [100, 1000]},\n",
       " 'DC': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.clf_small_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We also want to evaluate our models at the following thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [12, 16, 20]\n",
    "thresholds = [16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We run our models for each of our splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pipeline.clfs\n",
    "grid = pipeline.clf_small_grid\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'split',\n",
    "    'classifier',\n",
    "    'parameters',\n",
    "    'threshold'\n",
    "] + pipeline.evaluate.ClassifierEvaluator.metric_names())\n",
    "\n",
    "for i, (train_df, test_df) in enumerate(labeled_splits, start=1):\n",
    "    train_df = train_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    test_df = test_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    df = pipeline.run_clf_loop(\n",
    "        test_df, train_df, models, grid, 'label', thresholds, debug=False\n",
    "    )\n",
    "\n",
    "    df = df.assign(split=i)\n",
    "    results_df = results_df.append(df, ignore_index=True)\n",
    "\n",
    "results_df.to_csv('results/clf-small-grid_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models\n",
    "Our regression models are given by the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "          normalize=False),\n",
       " 'SVR': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "      intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "      random_state=None, tol=0.0001, verbose=0),\n",
       " 'DTR': DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       " 'RFR': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.regs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We plan to run a grid search using the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': {},\n",
       " 'SVR': {'C': [0.01, 0.1]},\n",
       " 'DTR': {'max_depth': [5, 50],\n",
       "  'max_features': [None],\n",
       "  'min_samples_split': [2, 5, 10]},\n",
       " 'RFR': {'n_estimators': [100, 1000],\n",
       "  'max_depth': [5, 50],\n",
       "  'max_features': ['sqrt', 'log2'],\n",
       "  'min_samples_split': [2, 5, 10]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.reg_small_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We run our models for each of our splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pipeline.regs\n",
    "grid = pipeline.reg_small_grid\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'split',\n",
    "    'classifier',\n",
    "    'parameters',\n",
    "] + pipeline.evaluate.RegressionEvaluator.metric_names())\n",
    "\n",
    "for i, (train_df, test_df) in enumerate(cleaned_splits, start=1):\n",
    "    train_df = train_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    test_df = test_df.drop(columns=['GEOID', 'year_evictions'])\n",
    "    df = pipeline.run_reg_loop(\n",
    "        test_df, train_df, models, grid, 'evictions'\n",
    "    )\n",
    "\n",
    "    df = df.assign(split=i)\n",
    "    results_df = results_df.append(df, ignore_index=True)\n",
    "\n",
    "results_df.to_csv('results/reg-small-grid_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
